{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise Empírica do algoritmo K-NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Implementação do classificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realização dos imports das bibliotecas\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def class_histogram(kn_neighbors, n_classes):\n",
    "    c = [0] * n_classes # custo constante\n",
    "\n",
    "    for i in kn_neighbors: # custo O(n)\n",
    "        c[i] += 1 # custo constante\n",
    "\n",
    "    return c # custo constante\n",
    "\n",
    "def knn(X_train, Y_train, x, k):\n",
    "    # Calcula o vetor de distâncias entre x e todos os pontos em X_train\n",
    "    d = euclidean_distances(x.reshape(1, -1), X_train).reshape(-1)\n",
    "\n",
    "    idx = np.argsort(d) # custo O(n lg n) (quick sort)\n",
    "\n",
    "    hist = class_histogram(Y_train[idx][:k], len(set(Y_train))) # custo O(n)\n",
    "    \n",
    "\n",
    "    return np.argmax(hist) # custo O(n)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Carregamento da base de dados de dígitos e divisão em treino e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 98.33%\n",
      "1.8132433891296387\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "\n",
    "X, Y = load_digits(return_X_y=True) # custo O(n)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, shuffle=True) # custo constante\n",
    "\n",
    "misses, hits = 0, 0 # custo constante\n",
    "k = 3 # custo constante\n",
    "              \n",
    "# laço que executa 540 vezes (30% da base)\n",
    "for i, x in enumerate(X_test): # custo O(n)\n",
    "    if knn(X_train, Y_train, x, k) == Y_test[i]:\n",
    "        hits += 1 # custo constante\n",
    "    else:\n",
    "        misses += 1 # custo constante\n",
    "        \n",
    "end = time.time()\n",
    "\n",
    "print (\"Acurácia: %.02f%%\" % (hits / float(hits + misses) * 100)) # custo constante\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Análise completa do algoritmo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Análise assintótica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* No que diz respeito ao *algoritmo K-NN*, foi verificado que ele segue um comportamento __O(n\\*lg\\*n)__. Para chegar a este resultado, foram considerados os seguintes pontos:\n",
    "  * A função *class\\_histogram* tem o seu desempenho definido por: **T(n) = c + n + c = O(n)**\n",
    "      * O termo *n* da soma é proveniente do laço for. Sua análise é trivial, visto que dada uma entrada de tamanho n para os vizinhos, o laço será executado n vezes.\n",
    "  * Já a função _knn_ tem o seu desempenho definido por: __T(n) = n + n\\*lg\\*n + n + n = O(n\\*lg\\*n)__\n",
    "      * O primeiro termo *n* da soma é proveniente da análise da função de distância euclidiana. Essa análise pode ser detalhada da seguinte maneira:\n",
    "          1. O conjunto passado como parâmetro para a função euclidiana é o conjunto de treino, que corresponde a 70% do total de dados da base de números. Logo, sendo _n_ o tamanho da base de dados, o conjunto de treino obedece à relação $\\frac{7n}{10}$, que também pode ter o seu tamanho representado como sendo *n*.\n",
    "          2. Assim, ao executar a função euclidiana é calculado o vetor distância entre um valor *x* passado como parâmetro e todos os pontos do conjunto de treino.\n",
    "          3. Analisando os parâmetros passados para a função euclidiana, tem-se que **x = 64** e **n = 1217**. Levando em consideração que as funções **reshape** tem custo constante, obtemos o seguinte comportamento: __T(n) = 64\\*c\\*n\\*c = 64\\*n = O(n)__\n",
    "      * Já o segundo termo, _n\\*lg\\*n_, corresponde a análise da função _argsort_ do _numpy_, que é embasada no algoritmo de ordenação _Quick Sort_, cujo desempenho é _n\\*lg\\*n_.\n",
    "      * O terceiro termo, *n*, provém da análise da função *class\\_histogram* descrita anteriormente.\n",
    "      * Por fim, o último termo *n* da soma corresponde ao desempenho da função *argmax* do *numpy*. Essa função retorna o índice do maior valor do array passado como parâmetro, por isso seu desempenho é *n*, pois é necessário percorrer um array de tamanho n.\n",
    "* Em relação ao algoritmo que efetua o *carregamento da base dados*, verificou-se que o seu comportamento é __T(n) = n + 3c + n\\*(n\\*lg\\*n) + c = O(n²\\*lg\\*n)__\n",
    "    * O primeiro *n* corresponde ao desempenho da função de carregamento do sklearn, que faz a leitura de uma base de tamanho n.\n",
    "    * O termo __n\\*(n\\*lg\\*n)__ provém do laço for que é executado n vezes (o n corresponde ao tamanho do conjunto designado para teste), sendo que em cada uma dessas vezes o algoritmo knn, que é __n\\*\\lg\\*n__, é invocado no if. Por isso existe a multiplicação, pois knn é invocado n vezes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Análise empírica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Para a formulação do custo total empírico, foram considerados os custos de load_digits(), laço externo, euclidian_distance, argsort, class_histogram(), argmax(), resultando no seguinte:\n",
    "\n",
    "    * __Custo empírico__ = O(n) + (O(0.3n) * (O(0.7n) + O(0.7n * lg * 0.7n) + O(0.7n) + O(0.7n)))\n",
    "\n",
    "* Como apresentado anteriormente, o custo assintótico é dado por:\n",
    "    * __Custo assintótico__ = O(n²\\*lg\\*n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Comparação entre análise assintótica e análise empírica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Para ilustrar a diferença do custo empírico e do custo assintótico, foi atribuído a *n* um valor de acordo com a quantidade de amostras total da base de dígitos. A tabela a seguir apresenta essa comparação.\n",
    "\n",
    "<style type=\"text/css\">\n",
    ".tg  {border-collapse:collapse;border-spacing:0;}\n",
    ".tg td{font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:black;}\n",
    ".tg th{font-family:Arial, sans-serif;font-size:14px;font-weight:normal;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:black;}\n",
    ".tg .tg-c3ow{border-color:inherit;text-align:center;vertical-align:top}\n",
    ".tg .tg-uys7{border-color:inherit;text-align:center}\n",
    "</style>\n",
    "<table class=\"tg\">\n",
    "  <tr>\n",
    "    <th class=\"tg-uys7\"><span style=\"font-weight:bold\">Entrada</span></th>\n",
    "    <th class=\"tg-uys7\"><span style=\"font-weight:bold\">Custo Assintótico</span></th>\n",
    "    <th class=\"tg-uys7\"><span style=\"font-weight:bold\">Custo empírico</span></th>\n",
    "    <th class=\"tg-uys7\"><span style=\"font-weight:bold\">Proporção</span></th>      \n",
    "      \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-uys7\">1797</td>\n",
    "    <td class=\"tg-uys7\">34 912 188.462654546</td>\n",
    "    <td class=\"tg-uys7\">9 367 758.247157454</td>\n",
    "    <td class=\"tg-uys7\">0.2683234325793731</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-uys7\">500</td>\n",
    "    <td class=\"tg-uys7\">2 241 446.0711655216</td>\n",
    "    <td class=\"tg-uys7\">628 703.6749447596</td>\n",
    "    <td class=\"tg-uys7\">0.2804902080993821</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-c3ow\">3400</td>\n",
    "    <td class=\"tg-c3ow\">135 614 047.99864975</td>\n",
    "    <td class=\"tg-c3ow\">35 765 150.079716444</td>\n",
    "    <td class=\"tg-c3ow\">0.26372747224588816</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-c3ow\"></td>\n",
    "    <td class=\"tg-c3ow\"></td>\n",
    "    <td class=\"tg-c3ow\"></td>\n",
    "    <td class=\"tg-c3ow\"></td>\n",
    "    <td class=\"tg-c3ow\"></td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "* A quantidade de amostras era __1797__ e, como se percebe pela tabela, o __custo empírico foi menor que o custo assintótico__, mostrando que o limite assintótico superior é obedecido, isto é, o custo empírico não superou o limite definido pelo custo assintótico.\n",
    "* Para verificar se a proporção se mantinha para outros casos, foram atribuídos mais dois valores para *n*: um menor que 1797 e outro maior. Novamente, o custo empírico foi menor que o custo assintótico e a proporção de, aproximadamente, __27%__ entre os dois tipos de custos foi mantida.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* O gráfico abaixo exibe os custos obtidos\n",
    "![Gráfico](./chart.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
